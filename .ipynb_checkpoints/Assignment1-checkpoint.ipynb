{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning</h1><h2 align=\"center\" style=\"margin:10px\">Assignment 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student names and numbers:\n",
    "# Raluca-Elena Petrovici 279998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignments below should be solved and documented as a mini-project that will form the basis for the\n",
    "examination. When solving the exercises it is important that you\n",
    "\n",
    "  * document all relevant results and analyses that you have obtained/performed during the exercises\n",
    "  * try to relate your results to the theoretical background of the methods being applied.\n",
    "\n",
    "Feel free to add cells if you need to. The easiest way to convert to pdf is to save this notebook as .html (File-->Download as-->HTML) and then convert this html file to pdf. You can also export as pdf directly, but here you need to watch your margins as the converter will cut off your code (i.e. make vertical code!).\n",
    "\n",
    "Last, but not least:\n",
    "* Looking for an overview of the markdown language? The cheat sheet <a href=\"https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\">here</a> might help.\n",
    "* For most of the Python specific components of the exercises, you should not need constructs beyond those that are already included in the notebooks on the course's web-page (still you should not feel constrained by these, so feel free to be adventurous). You may, however, need to consult the documentation for some of the methods supplied by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we investigate the Boston Housing dataset, which we treat as a classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "c = np.array([1 if y > np.median(data['target']) else 0 for y in data['target']])\n",
    "X_train, X_test, c_train, c_test = train_test_split(data['data'], c, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "**a)** Learn a decision tree using the training data and evaluate its performance on both the training data and the test data. Generate random training/test partitions or varying sizes and analyze how the accuracy results vary (consult the documentation for `train_test_split(.)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis\n",
    "\n",
    "**b)** Display the decision tree learned using the training data.\n",
    "\n",
    "**c)** What are the most important features as determined by the learned tree and does, e.g., the choice of top node seem reasonable to you?\n",
    "\n",
    "**d)** How does the features deemed *most important* by the decision tree learner match the generated tree and your understanding of house prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model complexity\n",
    "\n",
    "**e)** Try controlling the complexity of the learned decision tree by adjusting the parameters max\\_depth, min\\_samples\\_split, min\\_samples\\_leaf\n",
    "\n",
    "**f)** Investigate the effect when changing these parameters:\n",
    "    - Visualize (some of) the trees\n",
    "    - Evaluate the performance of the models on both the training data and the test data\n",
    "    \n",
    "**g)** Try to find good parameter values using cross-validation. How does the obtained parameters match your manual investigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Regression with random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will use the nycflights dataset (\"flights.csv\").\n",
    "\n",
    "So far, we have only considered how to use decision trees and random forests for classification. However, both algorithms can also be used for regression tasks, as we will see in the exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "**a)** Load the data, and consider how you want to handle missing values and categorical variables (you may choose to remove some features entirely). Carefully consider which variables are categorical. Normalize all relevant variables.\n",
    "\n",
    "**b)** In the following, we are going to determine which factors cause departure time delays, and try to predict the length of these delays. However, for several departures, a *negative* delay have been reported. How do you interpret a negative delay? Consider if you want to modify the negative delays in some way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression analysis: Predicting departure time delays\n",
    "\n",
    "**c)** Extract the features and the target variable (in this case the departure time delays) from the dataframe. Split the dataset into test and train sets (technically, we ought to have done this before preprocessing. For the sake of simplicity, we do not conform to this best practice in this exercise).\n",
    "\n",
    "**d)** Train a decision tree regressor for predicting departure time delays (you might want to experiment with a few different values of the hyperparameters to avoid too much overfitting). Plot the tree, and explain how decision trees can be used for regression analyses.\n",
    "\n",
    "**e)** Do a regression analysis as the one above, but using a random forest instead of a single decision tree. Use a grid-search to determine a good set of hyperparameters. When you have found the best model, score your model on the test set. Comment on the result. \n",
    "\n",
    "**f)** Plot the feature importances determined by the tree. Which feature is the most important? Do you have any idea as to why? Remove any features which cannot be used to predict departure time delays in any meaningful way, and redo the analysis. Comment on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression analysis: Predicting arrival time delays\n",
    "\n",
    "In the last part of the exercise, we are going to try to predict arrival time delays as a function of departure time delays - it might be of interest to know how large a delay one should expect after the plane has departed from the airport. \n",
    "\n",
    "**g)** Train a decision tree or random forest regressor and an OLS to the dataset, and see how well arrival time delay. can be predicted based on departure time delay. \n",
    "\n",
    "**h)** Plot the arrival time delays as a function of the departure time delay, and show the predictions from each of the two regressors.\n",
    "\n",
    "**i)** Based on the results obtained above, make a plot that extrapolates a little bit in order to predict delays slightly larger than the largest delay found in the dataset. Which model do you think gives the most trustworthy extrapolation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we perform character recognition using SVM classifiers. We use the MNIST dataset, which consists of 70000 handwritten digits 0-9 at a resolution of 28x28 pixels. In the cell below, the dataset is loaded and split into 60000 traning and 10000 testing images, and reshaped into the appropriate shape for an SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28*28)\n",
    "x_test = x_test.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code-snippet below can be used to see the images corresponding to individual digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = 1\n",
    "\n",
    "plt.imshow(x_train[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things a little bit simpler (and faster!), we can extract from the data binary subsets, that only contain the data for two selected digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "digit0=3\n",
    "digit1=7\n",
    "x_bin_train=x_train[np.logical_or(y_train==digit0,y_train==digit1)]\n",
    "y_bin_train=y_train[np.logical_or(y_train==digit0,y_train==digit1)]\n",
    "\n",
    "x_bin_test=x_test[np.logical_or(y_test==digit0,y_test==digit1)]\n",
    "y_bin_test=y_test[np.logical_or(y_test==digit0,y_test==digit1)]\n",
    "\n",
    "print(\"The first training datapoint now is: \\n\")\n",
    "plt.imshow(x_bin_train[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(y_bin_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an SVM model\n",
    "\n",
    "**a)** Learn different SVM models by varying e.g. the kernel functions and/or the C- and gamma-parameters. For each configuration, determine the time it takes to learn the model, and the accuracy on the test data. *Caution*: for some configurations, learning here can take a little while (several minutes).\n",
    "\n",
    "**b)** Inspect some misclassified cases. Do they correspond to hard to recognize digits (also for the human reader)? (Hint: you can e.g. use the numpy where() function to extract the indices of the test cases that were misclassified: `misclass = np.where(test != predictions)` )\n",
    " \n",
    "\n",
    "**c)** How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "**d)** Explain how a binary classifier, such as an SVM, can be applied to a multiclass classification problem, such as recognizing all 10 digits in the MNIST dataset (no coding required in this exercise!).\n",
    "\n",
    "**e)** Identify one or several good configurations that give a reasonable combination of accuracy and runtime. Use these configurations to perform a full classification of the 10 classes in the original dataset (after split into train/test). Using `sklearn.metrics.confusion_matrix` you can get an overview of all combinations of true and predicted labels (see p. 298-299 in Müller & Guido). What does this tell you about which digits are easy, and which ones are difficult to recognize, and which ones are most easily confused?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheating\n",
    "\n",
    "We next investigate the capability of the different learning approaches to find a good model, knowing that a very accurate model exists. For this, we add a 'cheat column' to our data: we add an additional column to the data matrix that simply contains a 0/1 encoding of the actual class label: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding cheating information to the training data:\n",
    "cheatcol_train=np.array(y_bin_train) #making a copy of the original target array\n",
    "cheatcol_train[cheatcol_train==digit0]=0  #re-coding the two classes as 0s and 1s\n",
    "cheatcol_train[cheatcol_train==digit1]=1\n",
    "cheatcol_train=cheatcol_train.reshape(-1,1) #getting the dimensions right for the following .hstack operation to work ... \n",
    "x_bin_cheat_train = np.hstack((x_bin_train,cheatcol_train))\n",
    "\n",
    "#adding cheating information to the training data:\n",
    "cheatcol_test=np.array(y_bin_test) #making a copy of the original target array\n",
    "cheatcol_test[cheatcol_test==digit0]=0  #re-coding the two classes as 0s and 1s\n",
    "cheatcol_test[cheatcol_test==digit1]=1\n",
    "cheatcol_test=cheatcol_test.reshape(-1,1) #getting the dimensions right for the following .hstack operation to work ... \n",
    "x_bin_cheat_test = np.hstack((x_bin_test,cheatcol_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM-model is, in principle, able to construct a 100% accurate classifier for this data: we only have to 'learn' that only the last column in the data matters. \n",
    "\n",
    "**f)** Describe, briefly, how the coefficients and weights of an SVM model would have to be set, so that the resulting model is 100% accurate on this cheating data. This part of the exercise does not involve any code. Just give your answer in a short text.\n",
    "\n",
    "**g)** Investigate how the accuracy of different SVM classifiers improves in practice on this new dataset. Do you achieve 100% accuracy on the test set? If not, try to change the encoding in the cheat column: instead of representing digit1 with a 1, use a larger number, e.g. 250. Does that help? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Data exploration and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to investigate student dropout based on the dataset \"churn.cvs\". This is a real dataset, and there is no single \"correct\" way to use it (however, there are several wrong ones!). Your exercise is to explore one or more possible use cases, and document the one(s) you find the most fruitful/interesting.  Your work should probably include the steps below:\n",
    "\n",
    "- An investigation of the data, using e.g. FACETs, Pandas, and/or whatever other tools you prefer. Can you find any interesting correlations? Are there problematic features or rows in the dataset?\n",
    "- Handle missing data and possible outliers (in each case, consider what you want to do: Remove row? Remove column? Insert custom value?).\n",
    "- Normalize/bin/create dummy variables where relevant. \n",
    "- Determine what you would like to predict, i.e. choose your target variable. Try formulating a specific usecase for your experiment (e.g. \"Given a students perfomance in high school and first semester, what is the probability that he/she churns in the 2. semester?\")\n",
    "- Train a logistic regression and at least one other algorithm on the data. Use either manual tuning or cross validation to find a good set of hyperparameters for each model. Do you see any specific advantages in using a logistic regression in this case?\n",
    "- What features seem to be important for predicting whether a student is likely to drop out?\n",
    "\n",
    "Warning: Make sure you carefully consider what information is available at the time where a prediction is to be made - for example, it doesn't make any sense to try to predict if a student churns in semester 1, if you include a feature which tells that this student churned in semester 2!  So depending on your specific use case, you should probably remove some columns and/or rows before you train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will predict if a student will drop out (churned_all), based on their admission data (all columns, excluding the first semester fields), so that a university could use a student's data prior to admission to estimate whether that student is likely to drop out or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Age_at_studystart</th>\n",
       "      <th>Study_programme</th>\n",
       "      <th>Study_programme_code</th>\n",
       "      <th>Studystart_date</th>\n",
       "      <th>Studystart_month</th>\n",
       "      <th>Studystart_year</th>\n",
       "      <th>Studyend_month</th>\n",
       "      <th>Studyend_year</th>\n",
       "      <th>University_institute</th>\n",
       "      <th>...</th>\n",
       "      <th>Passed_ects_SEM1</th>\n",
       "      <th>Grade_point_average_SEM1</th>\n",
       "      <th>SU_clips_used</th>\n",
       "      <th>Years_since_exam</th>\n",
       "      <th>CHURNED_ALL</th>\n",
       "      <th>CHURNED_IN_SEM1</th>\n",
       "      <th>CHURNED_IN_SEM2</th>\n",
       "      <th>CHURNED_AFTER_SEM1</th>\n",
       "      <th>CHURNED_AFTER_SEM2</th>\n",
       "      <th>CHURNED_SEM2THROUGHSEM3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.7</td>\n",
       "      <td>litteraturvidenskab</td>\n",
       "      <td>HFMA00001T</td>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Saxo-Instituttet - Arkaeologi. Etnologi. Histo...</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>22.4</td>\n",
       "      <td>dansk</td>\n",
       "      <td>HRVA00001T</td>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Institut for Kunst og Kulturvidenskab</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.9</td>\n",
       "      <td>informationsvidenskab og kulturformidling</td>\n",
       "      <td>HTEA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Saxo-Instituttet - Arkaeologi. Etnologi. Histo...</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>21.3</td>\n",
       "      <td>paedagogik</td>\n",
       "      <td>HTEA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Institut for Engelsk. Germansk og Romansk</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sverige</td>\n",
       "      <td>19.9</td>\n",
       "      <td>audiologopaedi</td>\n",
       "      <td>HKMA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Institut for Medier. Erkendelse og Formidling</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>24.2</td>\n",
       "      <td>informationsvidenskab og kulturformidling</td>\n",
       "      <td>HFRA00001T</td>\n",
       "      <td>9/1/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Institut for Tvaerkulturelle og regionale studier</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>61.6</td>\n",
       "      <td>koreastudier</td>\n",
       "      <td>HDAA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Institut for Kunst og Kulturvidenskab</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>23.3</td>\n",
       "      <td>kinastudier</td>\n",
       "      <td>HENA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Institut for Nordiske Studier og Sprogvidenskab</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.63</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>22.1</td>\n",
       "      <td>dansk</td>\n",
       "      <td>HHIA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Institut for Engelsk. Germansk og Romansk</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.2</td>\n",
       "      <td>moderne Indien og sydasienstudier</td>\n",
       "      <td>HSPA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>IVA</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nationality  Age_at_studystart  \\\n",
       "0        Danmark               20.7   \n",
       "1        Danmark               22.4   \n",
       "2        Danmark               20.9   \n",
       "3        Danmark               21.3   \n",
       "4        Sverige               19.9   \n",
       "...          ...                ...   \n",
       "1995     Danmark               24.2   \n",
       "1996     Danmark               61.6   \n",
       "1997     Danmark               23.3   \n",
       "1998     Danmark               22.1   \n",
       "1999     Danmark               20.2   \n",
       "\n",
       "                                Study_programme Study_programme_code  \\\n",
       "0                           litteraturvidenskab           HFMA00001T   \n",
       "1                                         dansk           HRVA00001T   \n",
       "2     informationsvidenskab og kulturformidling           HTEA00001T   \n",
       "3                                    paedagogik           HTEA00001T   \n",
       "4                                audiologopaedi           HKMA00001T   \n",
       "...                                         ...                  ...   \n",
       "1995  informationsvidenskab og kulturformidling           HFRA00001T   \n",
       "1996                               koreastudier           HDAA00001T   \n",
       "1997                                kinastudier           HENA00001T   \n",
       "1998                                      dansk           HHIA00001T   \n",
       "1999          moderne Indien og sydasienstudier           HSPA00001T   \n",
       "\n",
       "     Studystart_date  Studystart_month  Studystart_year  Studyend_month  \\\n",
       "0           9/1/2013                 9             2013             4.0   \n",
       "1           9/1/2013                 9             2013             9.0   \n",
       "2           9/1/2014                 9             2013             7.0   \n",
       "3           9/1/2016                 9             2013             9.0   \n",
       "4           9/1/2014                 9             2013             8.0   \n",
       "...              ...               ...              ...             ...   \n",
       "1995        9/1/2015                 9             2016             NaN   \n",
       "1996        9/1/2016                 9             2016             NaN   \n",
       "1997        9/1/2016                 9             2016            12.0   \n",
       "1998        9/1/2014                 9             2016             NaN   \n",
       "1999        9/1/2016                 9             2016            11.0   \n",
       "\n",
       "      Studyend_year                               University_institute  ...  \\\n",
       "0            2013.0  Saxo-Instituttet - Arkaeologi. Etnologi. Histo...  ...   \n",
       "1            2015.0              Institut for Kunst og Kulturvidenskab  ...   \n",
       "2            2015.0  Saxo-Instituttet - Arkaeologi. Etnologi. Histo...  ...   \n",
       "3            2014.0          Institut for Engelsk. Germansk og Romansk  ...   \n",
       "4            2015.0      Institut for Medier. Erkendelse og Formidling  ...   \n",
       "...             ...                                                ...  ...   \n",
       "1995            NaN  Institut for Tvaerkulturelle og regionale studier  ...   \n",
       "1996            NaN              Institut for Kunst og Kulturvidenskab  ...   \n",
       "1997         2016.0    Institut for Nordiske Studier og Sprogvidenskab  ...   \n",
       "1998            NaN          Institut for Engelsk. Germansk og Romansk  ...   \n",
       "1999         2016.0                                                IVA  ...   \n",
       "\n",
       "     Passed_ects_SEM1  Grade_point_average_SEM1  SU_clips_used  \\\n",
       "0                30.0                      7.00           30.0   \n",
       "1                30.0                      0.00            NaN   \n",
       "2                30.0                      7.75           14.0   \n",
       "3                 0.0                      7.00            NaN   \n",
       "4                 0.0                      0.00            NaN   \n",
       "...               ...                       ...            ...   \n",
       "1995             30.0                      9.23            6.0   \n",
       "1996             30.0                      4.38            6.0   \n",
       "1997              0.0                     10.63            6.0   \n",
       "1998             30.0                      4.36           30.0   \n",
       "1999             30.0                     12.00            NaN   \n",
       "\n",
       "     Years_since_exam CHURNED_ALL  CHURNED_IN_SEM1  CHURNED_IN_SEM2  \\\n",
       "0                   1           1                1                0   \n",
       "1                   1           0                0                0   \n",
       "2                   1           0                1                0   \n",
       "3                  23           0                1                0   \n",
       "4                   3           1                1                0   \n",
       "...               ...         ...              ...              ...   \n",
       "1995                0           0                0                0   \n",
       "1996               -1           0                1                0   \n",
       "1997                0           1                0                0   \n",
       "1998                1           0                0                0   \n",
       "1999                5           1                1                0   \n",
       "\n",
       "      CHURNED_AFTER_SEM1  CHURNED_AFTER_SEM2  CHURNED_SEM2THROUGHSEM3  \n",
       "0                      0                   0                        0  \n",
       "1                      0                   0                        0  \n",
       "2                      0                   0                        0  \n",
       "3                      0                   0                        0  \n",
       "4                      1                   1                        0  \n",
       "...                  ...                 ...                      ...  \n",
       "1995                   0                   0                        0  \n",
       "1996                   0                   0                        0  \n",
       "1997                   0                   0                        0  \n",
       "1998                   0                   0                        0  \n",
       "1999                   0                   0                        0  \n",
       "\n",
       "[2000 rows x 27 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "data = pd.read_csv(\"churn.csv\")\n",
    "# plt.figure(figsize=(16,10))\n",
    "# sns.heatmap(data.corr(), annot=True)\n",
    "# plt.show()\n",
    "# data.corr()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nationality', 'Age_at_studystart', 'Study_programme',\n",
      "       'Study_programme_code', 'Studystart_date', 'Studystart_month',\n",
      "       'Studystart_year', 'Studyend_month', 'Studyend_year',\n",
      "       'University_institute', 'Status', 'Exam_year',\n",
      "       'Exam_grade_point_average', 'Grading_scale', 'Exam_type',\n",
      "       'Priority_number', 'Quote', 'Passed_ects_SEM1',\n",
      "       'Grade_point_average_SEM1', 'SU_clips_used', 'Years_since_exam',\n",
      "       'CHURNED_ALL', 'CHURNED_IN_SEM1', 'CHURNED_IN_SEM2',\n",
      "       'CHURNED_AFTER_SEM1', 'CHURNED_AFTER_SEM2', 'CHURNED_SEM2THROUGHSEM3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nationality', 'Age_at_studystart', 'Study_programme',\n",
      "       'Study_programme_code', 'Studystart_date', 'Studystart_month',\n",
      "       'Studystart_year', 'University_institute', 'Exam_year',\n",
      "       'Exam_grade_point_average', 'Grading_scale', 'Exam_type',\n",
      "       'Priority_number', 'Quote', 'Years_since_exam', 'CHURNED_ALL',\n",
      "       'CHURNED_IN_SEM1', 'CHURNED_IN_SEM2', 'CHURNED_AFTER_SEM1',\n",
      "       'CHURNED_AFTER_SEM2', 'CHURNED_SEM2THROUGHSEM3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# the columns that are irrelevant and can be dropped right away are: Studyend_month, Studyend_year, Status, Passed_ects_SEM1, Grade_point_average_SEM1, SU_clips_used\n",
    "\n",
    "data=data.drop(columns=['Studyend_month', 'Studyend_year', 'Status', 'Passed_ects_SEM1', 'Grade_point_average_SEM1', 'SU_clips_used'])\n",
    "\n",
    "#columns that are irrelevant, but need are needed for data preparation: 'CHURNED_IN_SEM1', 'CHURNED_IN_SEM2', 'CHURNED_AFTER_SEM1', 'CHURNED_AFTER_SEM2', 'CHURNED_SEM2THROUGHSEM3'\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#handling missing data first\n",
    "#checking that these columns don't have nulls\n",
    "print(data['Nationality'].isnull().values.any())\n",
    "print(data['Study_programme'].isnull().values.any())\n",
    "print(data['Studystart_date'].isnull().values.any())\n",
    "print(data['Studystart_month'].isnull().values.any())\n",
    "print(data['Studystart_year'].isnull().values.any())\n",
    "print(data['Exam_year'].isnull().values.any())\n",
    "print(data['Exam_grade_point_average'].isnull().values.any())\n",
    "print(data['Years_since_exam'].isnull().values.any())\n",
    "print(data['CHURNED_ALL'].isnull().values.any())\n",
    "print(data['CHURNED_IN_SEM1'].isnull().values.any())\n",
    "print(data['CHURNED_IN_SEM2'].isnull().values.any())\n",
    "print(data['CHURNED_AFTER_SEM1'].isnull().values.any())\n",
    "print(data['CHURNED_AFTER_SEM2'].isnull().values.any())\n",
    "print(data['CHURNED_SEM2THROUGHSEM3'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in Quote:  86\n",
      "Number of null values in Grading_scale:  58\n",
      "Number of null values in Exam_type:  68\n",
      "Number of null values in Priority_number:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.0\n",
       "2       21.0\n",
       "3        6.0\n",
       "4        1.0\n",
       "        ... \n",
       "1995     1.0\n",
       "1996     1.0\n",
       "1997     1.0\n",
       "1998     1.0\n",
       "1999     1.0\n",
       "Name: Priority_number, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of null values in Quote: \", data['Quote'].isnull().sum())\n",
    "print(\"Number of null values in Grading_scale: \", data['Grading_scale'].isnull().sum())\n",
    "print(\"Number of null values in Exam_type: \", data['Exam_type'].isnull().sum())\n",
    "print(\"Number of null values in Priority_number: \", data['Priority_number'].isnull().sum())\n",
    "\n",
    "#for the missing priority number, we'll just insert the mode value of the column\n",
    "data['Priority_number'].fillna(data['Priority_number'].mode().iat[0])\n",
    "\n",
    "# Quote, Grading_scale and Exam_type are important features, and we don't want to badly assume their values and build a bad model, so we want to drop the entries that have null values in these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only one student without a known age in the dataset, we can safely drop that entry. We could also add a dummy value, like the mean, or mode of the Age_at_studystart column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in Age_at_studystart:  1\n",
      "Number of null values in Age_at_studystart:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in Age_at_studystart: \", data['Age_at_studystart'].isnull().sum())\n",
    "data['Age_at_studystart'] = data['Age_at_studystart'].fillna(data['Age_at_studystart'].mode()[0])\n",
    "print(\"Number of null values in Age_at_studystart: \", data['Age_at_studystart'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University_institute has one missing value, so we will just drop the entry later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in University_institute:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in University_institute: \", data['University_institute'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all of the columns with null values that we wanted to handle were handled, so we can drop the entries with null values in the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1795, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Age_at_studystart</th>\n",
       "      <th>Study_programme</th>\n",
       "      <th>Study_programme_code</th>\n",
       "      <th>Studystart_date</th>\n",
       "      <th>Studystart_month</th>\n",
       "      <th>Studystart_year</th>\n",
       "      <th>University_institute</th>\n",
       "      <th>Exam_year</th>\n",
       "      <th>Exam_grade_point_average</th>\n",
       "      <th>...</th>\n",
       "      <th>Exam_type</th>\n",
       "      <th>Priority_number</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Years_since_exam</th>\n",
       "      <th>CHURNED_ALL</th>\n",
       "      <th>CHURNED_IN_SEM1</th>\n",
       "      <th>CHURNED_IN_SEM2</th>\n",
       "      <th>CHURNED_AFTER_SEM1</th>\n",
       "      <th>CHURNED_AFTER_SEM2</th>\n",
       "      <th>CHURNED_SEM2THROUGHSEM3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.7</td>\n",
       "      <td>litteraturvidenskab</td>\n",
       "      <td>HFMA00001T</td>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>Saxo-Instituttet - Arkaeologi. Etnologi. Histo...</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>22.4</td>\n",
       "      <td>dansk</td>\n",
       "      <td>HRVA00001T</td>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>Institut for Kunst og Kulturvidenskab</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.9</td>\n",
       "      <td>informationsvidenskab og kulturformidling</td>\n",
       "      <td>HTEA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>Saxo-Instituttet - Arkaeologi. Etnologi. Histo...</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>21.3</td>\n",
       "      <td>paedagogik</td>\n",
       "      <td>HTEA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>Institut for Engelsk. Germansk og Romansk</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sverige</td>\n",
       "      <td>19.9</td>\n",
       "      <td>audiologopaedi</td>\n",
       "      <td>HKMA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>Institut for Medier. Erkendelse og Formidling</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>24.2</td>\n",
       "      <td>informationsvidenskab og kulturformidling</td>\n",
       "      <td>HFRA00001T</td>\n",
       "      <td>9/1/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>Institut for Tvaerkulturelle og regionale studier</td>\n",
       "      <td>2014</td>\n",
       "      <td>11.3</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>61.6</td>\n",
       "      <td>koreastudier</td>\n",
       "      <td>HDAA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>Institut for Kunst og Kulturvidenskab</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>23.3</td>\n",
       "      <td>kinastudier</td>\n",
       "      <td>HENA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>Institut for Nordiske Studier og Sprogvidenskab</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.7</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>22.1</td>\n",
       "      <td>dansk</td>\n",
       "      <td>HHIA00001T</td>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>Institut for Engelsk. Germansk og Romansk</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Danmark</td>\n",
       "      <td>20.2</td>\n",
       "      <td>moderne Indien og sydasienstudier</td>\n",
       "      <td>HSPA00001T</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>IVA</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.8</td>\n",
       "      <td>...</td>\n",
       "      <td>Studentereksamen (2008 og senere)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nationality  Age_at_studystart  \\\n",
       "0        Danmark               20.7   \n",
       "1        Danmark               22.4   \n",
       "2        Danmark               20.9   \n",
       "3        Danmark               21.3   \n",
       "4        Sverige               19.9   \n",
       "...          ...                ...   \n",
       "1995     Danmark               24.2   \n",
       "1996     Danmark               61.6   \n",
       "1997     Danmark               23.3   \n",
       "1998     Danmark               22.1   \n",
       "1999     Danmark               20.2   \n",
       "\n",
       "                                Study_programme Study_programme_code  \\\n",
       "0                           litteraturvidenskab           HFMA00001T   \n",
       "1                                         dansk           HRVA00001T   \n",
       "2     informationsvidenskab og kulturformidling           HTEA00001T   \n",
       "3                                    paedagogik           HTEA00001T   \n",
       "4                                audiologopaedi           HKMA00001T   \n",
       "...                                         ...                  ...   \n",
       "1995  informationsvidenskab og kulturformidling           HFRA00001T   \n",
       "1996                               koreastudier           HDAA00001T   \n",
       "1997                                kinastudier           HENA00001T   \n",
       "1998                                      dansk           HHIA00001T   \n",
       "1999          moderne Indien og sydasienstudier           HSPA00001T   \n",
       "\n",
       "     Studystart_date  Studystart_month  Studystart_year  \\\n",
       "0           9/1/2013                 9             2013   \n",
       "1           9/1/2013                 9             2013   \n",
       "2           9/1/2014                 9             2013   \n",
       "3           9/1/2016                 9             2013   \n",
       "4           9/1/2014                 9             2013   \n",
       "...              ...               ...              ...   \n",
       "1995        9/1/2015                 9             2016   \n",
       "1996        9/1/2016                 9             2016   \n",
       "1997        9/1/2016                 9             2016   \n",
       "1998        9/1/2014                 9             2016   \n",
       "1999        9/1/2016                 9             2016   \n",
       "\n",
       "                                   University_institute  Exam_year  \\\n",
       "0     Saxo-Instituttet - Arkaeologi. Etnologi. Histo...       2013   \n",
       "1                 Institut for Kunst og Kulturvidenskab       2015   \n",
       "2     Saxo-Instituttet - Arkaeologi. Etnologi. Histo...       2013   \n",
       "3             Institut for Engelsk. Germansk og Romansk       2012   \n",
       "4         Institut for Medier. Erkendelse og Formidling       2012   \n",
       "...                                                 ...        ...   \n",
       "1995  Institut for Tvaerkulturelle og regionale studier       2014   \n",
       "1996              Institut for Kunst og Kulturvidenskab       2014   \n",
       "1997    Institut for Nordiske Studier og Sprogvidenskab       2008   \n",
       "1998          Institut for Engelsk. Germansk og Romansk       2012   \n",
       "1999                                                IVA       2014   \n",
       "\n",
       "      Exam_grade_point_average  ...                          Exam_type  \\\n",
       "0                          8.0  ...  Studentereksamen (2008 og senere)   \n",
       "1                          4.9  ...  Studentereksamen (2008 og senere)   \n",
       "2                          4.8  ...                   Studentereksamen   \n",
       "3                          4.1  ...  Studentereksamen (2008 og senere)   \n",
       "4                          8.5  ...  Studentereksamen (2008 og senere)   \n",
       "...                        ...  ...                                ...   \n",
       "1995                      11.3  ...  Studentereksamen (2008 og senere)   \n",
       "1996                       0.0  ...                   Studentereksamen   \n",
       "1997                       2.7  ...  Studentereksamen (2008 og senere)   \n",
       "1998                       6.8  ...  Studentereksamen (2008 og senere)   \n",
       "1999                       9.8  ...  Studentereksamen (2008 og senere)   \n",
       "\n",
       "     Priority_number  Quote  Years_since_exam  CHURNED_ALL  CHURNED_IN_SEM1  \\\n",
       "0                1.0    2.0                 1            1                1   \n",
       "1                1.0    1.0                 1            0                0   \n",
       "2               21.0    1.0                 1            0                1   \n",
       "3                6.0    1.0                23            0                1   \n",
       "4                1.0    1.0                 3            1                1   \n",
       "...              ...    ...               ...          ...              ...   \n",
       "1995             1.0    1.0                 0            0                0   \n",
       "1996             1.0    1.0                -1            0                1   \n",
       "1997             1.0    1.0                 0            1                0   \n",
       "1998             1.0    1.0                 1            0                0   \n",
       "1999             1.0    1.0                 5            1                1   \n",
       "\n",
       "      CHURNED_IN_SEM2  CHURNED_AFTER_SEM1  CHURNED_AFTER_SEM2  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   1                   1   \n",
       "...               ...                 ...                 ...   \n",
       "1995                0                   0                   0   \n",
       "1996                0                   0                   0   \n",
       "1997                0                   0                   0   \n",
       "1998                0                   0                   0   \n",
       "1999                0                   0                   0   \n",
       "\n",
       "      CHURNED_SEM2THROUGHSEM3  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "1995                        0  \n",
       "1996                        0  \n",
       "1997                        0  \n",
       "1998                        0  \n",
       "1999                        0  \n",
       "\n",
       "[1795 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that CHURNED_ALL column is filled with 1 only if one of the other CHURNED_* fields are filled with one. If the others are all 0, and CHURNED_ALL is 1, then we drop the entry. If CHURNED_ALL is 0, but any of the others are true, we drop it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795\n",
      "     Nationality  Age_at_studystart  \\\n",
      "0        Danmark               20.7   \n",
      "1        Danmark               22.4   \n",
      "2        Danmark               20.9   \n",
      "3        Danmark               21.3   \n",
      "4        Sverige               19.9   \n",
      "...          ...                ...   \n",
      "1995     Danmark               24.2   \n",
      "1996     Danmark               61.6   \n",
      "1997     Danmark               23.3   \n",
      "1998     Danmark               22.1   \n",
      "1999     Danmark               20.2   \n",
      "\n",
      "                                Study_programme Study_programme_code  \\\n",
      "0                           litteraturvidenskab           HFMA00001T   \n",
      "1                                         dansk           HRVA00001T   \n",
      "2     informationsvidenskab og kulturformidling           HTEA00001T   \n",
      "3                                    paedagogik           HTEA00001T   \n",
      "4                                audiologopaedi           HKMA00001T   \n",
      "...                                         ...                  ...   \n",
      "1995  informationsvidenskab og kulturformidling           HFRA00001T   \n",
      "1996                               koreastudier           HDAA00001T   \n",
      "1997                                kinastudier           HENA00001T   \n",
      "1998                                      dansk           HHIA00001T   \n",
      "1999          moderne Indien og sydasienstudier           HSPA00001T   \n",
      "\n",
      "     Studystart_date  Studystart_month  Studystart_year  \\\n",
      "0           9/1/2013                 9             2013   \n",
      "1           9/1/2013                 9             2013   \n",
      "2           9/1/2014                 9             2013   \n",
      "3           9/1/2016                 9             2013   \n",
      "4           9/1/2014                 9             2013   \n",
      "...              ...               ...              ...   \n",
      "1995        9/1/2015                 9             2016   \n",
      "1996        9/1/2016                 9             2016   \n",
      "1997        9/1/2016                 9             2016   \n",
      "1998        9/1/2014                 9             2016   \n",
      "1999        9/1/2016                 9             2016   \n",
      "\n",
      "                                   University_institute  Exam_year  \\\n",
      "0     Saxo-Instituttet - Arkaeologi. Etnologi. Histo...       2013   \n",
      "1                 Institut for Kunst og Kulturvidenskab       2015   \n",
      "2     Saxo-Instituttet - Arkaeologi. Etnologi. Histo...       2013   \n",
      "3             Institut for Engelsk. Germansk og Romansk       2012   \n",
      "4         Institut for Medier. Erkendelse og Formidling       2012   \n",
      "...                                                 ...        ...   \n",
      "1995  Institut for Tvaerkulturelle og regionale studier       2014   \n",
      "1996              Institut for Kunst og Kulturvidenskab       2014   \n",
      "1997    Institut for Nordiske Studier og Sprogvidenskab       2008   \n",
      "1998          Institut for Engelsk. Germansk og Romansk       2012   \n",
      "1999                                                IVA       2014   \n",
      "\n",
      "      Exam_grade_point_average  ...                          Exam_type  \\\n",
      "0                          8.0  ...  Studentereksamen (2008 og senere)   \n",
      "1                          4.9  ...  Studentereksamen (2008 og senere)   \n",
      "2                          4.8  ...                   Studentereksamen   \n",
      "3                          4.1  ...  Studentereksamen (2008 og senere)   \n",
      "4                          8.5  ...  Studentereksamen (2008 og senere)   \n",
      "...                        ...  ...                                ...   \n",
      "1995                      11.3  ...  Studentereksamen (2008 og senere)   \n",
      "1996                       0.0  ...                   Studentereksamen   \n",
      "1997                       2.7  ...  Studentereksamen (2008 og senere)   \n",
      "1998                       6.8  ...  Studentereksamen (2008 og senere)   \n",
      "1999                       9.8  ...  Studentereksamen (2008 og senere)   \n",
      "\n",
      "     Priority_number  Quote  Years_since_exam  CHURNED_ALL  CHURNED_IN_SEM1  \\\n",
      "0                1.0    2.0                 1            1                1   \n",
      "1                1.0    1.0                 1            0                0   \n",
      "2               21.0    1.0                 1            0                1   \n",
      "3                6.0    1.0                23            0                1   \n",
      "4                1.0    1.0                 3            1                1   \n",
      "...              ...    ...               ...          ...              ...   \n",
      "1995             1.0    1.0                 0            0                0   \n",
      "1996             1.0    1.0                -1            0                1   \n",
      "1997             1.0    1.0                 0            1                0   \n",
      "1998             1.0    1.0                 1            0                0   \n",
      "1999             1.0    1.0                 5            1                1   \n",
      "\n",
      "      CHURNED_IN_SEM2  CHURNED_AFTER_SEM1  CHURNED_AFTER_SEM2  \\\n",
      "0                   0                   0                   0   \n",
      "1                   0                   0                   0   \n",
      "2                   0                   0                   0   \n",
      "3                   0                   0                   0   \n",
      "4                   0                   1                   1   \n",
      "...               ...                 ...                 ...   \n",
      "1995                0                   0                   0   \n",
      "1996                0                   0                   0   \n",
      "1997                0                   0                   0   \n",
      "1998                0                   0                   0   \n",
      "1999                0                   0                   0   \n",
      "\n",
      "      CHURNED_SEM2THROUGHSEM3  \n",
      "0                           0  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "...                       ...  \n",
      "1995                        0  \n",
      "1996                        0  \n",
      "1997                        0  \n",
      "1998                        0  \n",
      "1999                        0  \n",
      "\n",
      "[1795 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Installations\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-efcd8feaf250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHURNED_IN_SEM1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# for i in range(len(data.index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     if (data.at[i,'CHURNED_IN_SEM1'] == 1 or data.at[i,'CHURNED_IN_SEM2'] == 1 or data.at[i,'CHURNED_AFTER_SEM1'] == 1 or data.at[i,'CHURNED_AFTER_SEM2'] == 1 or data.at[i,'CHURNED_SEM2THROUGHSEM3'] == 1) and data.at[i,'CHURNED_ALL'] == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installations\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installations\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "data.reset_index\n",
    "print(len(data.index))\n",
    "print(data)\n",
    "data[0]['CHURNED_IN_SEM1']\n",
    "# for i in range(len(data.index)\n",
    "#     if (data.at[i,'CHURNED_IN_SEM1'] == 1 or data.at[i,'CHURNED_IN_SEM2'] == 1 or data.at[i,'CHURNED_AFTER_SEM1'] == 1 or data.at[i,'CHURNED_AFTER_SEM2'] == 1 or data.at[i,'CHURNED_SEM2THROUGHSEM3'] == 1) and data.at[i,'CHURNED_ALL'] == 0:\n",
    "#         data.drop(i)\n",
    "#     if (data.at[i,'CHURNED_IN_SEM1'] == 0 and data.at(i,'CHURNED_IN_SEM2') == 0 and data.at(i,'CHURNED_AFTER_SEM1') == 0 and data.at(i,'CHURNED_AFTER_SEM2') == 0 and data.at(i,'CHURNED_SEM2THROUGHSEM3') == 0) and data.at(i,'CHURNED_ALL') == 1:\n",
    "#                data.drop(i)\n",
    "# print(len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies and then find correlations (correlations won't work if you don't have integer values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression with cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the important features - use PCL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
